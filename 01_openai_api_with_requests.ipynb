{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# we read our API keys from .env - I have a .env.sample for you, just rename to .env\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b8cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a90e8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selected: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# We select our model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(f\"Model selected: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949f018",
   "metadata": {},
   "source": [
    "For demo, we will create our own OpenAI request but in future we will use the OpenAI library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1226148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are essentially making a POST request to one endpoint and we create a convenience Class to pass in prompts, temperature and model.\n",
    "\n",
    "# Temperature - The OpenAI API incorporates a hyperparameter known as temperature that affects the computation of token probabilities when generating output through the large language model. The temperature value ranges from 0 to 2, with lower values indicating greater determinism and higher values indicating more randomness.\n",
    "\n",
    "\n",
    "class MyCustomOpenAI:\n",
    "\n",
    "    def __init__(self, system_prompt=None, temperature=0.5, model=MODEL):\n",
    "\n",
    "        self.model_endpoint = \"https://api.openai.com/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.api_key = openai_api_key\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "        }\n",
    "\n",
    "    def generate_text(self, prompt):\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        # Use HTTP POST method from Requests library\n",
    "        response = requests.post(\n",
    "            self.model_endpoint, headers=self.headers, data=json.dumps(payload)\n",
    "        ).json()\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548bb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an instance of MyCustomOpenAI and pass in a request\n",
    "\n",
    "client = MyCustomOpenAI(\n",
    "    model=MODEL,\n",
    "    system_prompt=\"You give concise answers to questions with no more than 100 characters\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "response = client.generate_text(\"What is Pydantic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39feb11",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(response[\"choices\"][0])\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(response[\"choices\"][0][\"message\"])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(response[\"choices\"][0][\"message\"][\"content\"])\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "# print(response)\n",
    "# print(response[\"choices\"][0])\n",
    "# print(response[\"choices\"][0][\"message\"])\n",
    "# print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"].replace(\"\\n\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8ee55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
